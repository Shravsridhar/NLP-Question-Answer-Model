{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biredctional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import io\n",
    "import nltk\n",
    "import h5py\n",
    "import keras as k\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Dense, Dropout, RepeatVector, Activation, merge, Lambda, Flatten, Reshape\n",
    "from keras.layers import LSTM, Bidirectional, TimeDistributed, GRU\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import concatenate\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATING EMBEDING LAYER WITH HELP OF WORD EMBEDDINGS: GLOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open( 'glove.6B.100d.txt',encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT VECTORIZED FILES FOR CONTEXT, QUESTIONS, ANSWERS POST PREPROCESS OF DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = h5py.File('context.h5','r')\n",
    "questions = h5py.File('questions.h5','r')\n",
    "answers = h5py.File('answers.h5','r')\n",
    "ans_begin = h5py.File('begin.h5','r')\n",
    "ans_end = h5py.File('end.h5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_data = context['context'][:]\n",
    "qn_data = questions['questions'][:]\n",
    "ans_data = answers['answers'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_ans = ans_begin['begin'][:]\n",
    "end_ans = ans_end['end'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loding vocabulary\n",
    "word_index = np.load('words.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, 100))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word_index) + 1\n",
    "#embedding_vector_length = 50\n",
    "batch_size = 64\n",
    "max_span_begin = np.amax(begin_ans)\n",
    "max_span_end = np.amax(end_ans)\n",
    "train = 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "119616"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Vocab Size\")\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL CREATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_input = Input(shape=(700, ), dtype='int32', name='c_data')\n",
    "embed_c = Embedding(input_dim=vocab_size, output_dim=100, weights=[embedding_matrix], \n",
    "              input_length=700, trainable=False)(context_input)\n",
    "bidir_c = Bidirectional(LSTM(256, return_sequences=True, implementation=2), merge_mode='concat')(embed_c)\n",
    "drop_1 = Dropout(0.5)(bidir_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques_input = Input(shape=(100, ), dtype='int32', name='qn_data')\n",
    "embed_q = Embedding(input_dim=vocab_size, output_dim=100, weights=[embedding_matrix], \n",
    "              input_length=100, trainable=False)(ques_input)\n",
    "bidir_q = Bidirectional(LSTM(256, return_sequences=True, implementation=2), merge_mode='concat')(embed_q)\n",
    "drop_2 = Dropout(0.5)(bidir_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "c_data (InputLayer)             (None, 700)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "qn_data (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 700, 100)     11961600    c_data[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 100, 100)     11961600    qn_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 700, 512)     731136      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 100, 512)     731136      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 700, 512)     0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 100, 512)     0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 800, 512)     0           dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 256)          1574912     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3126)         803382      bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3136)         805952      bidirectional_3[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 28,569,718\n",
      "Trainable params: 4,646,518\n",
      "Non-trainable params: 23,923,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "merge_layer = concatenate([drop_1, drop_2], axis=1)\n",
    "bidir_m = Bidirectional(LSTM(256, implementation=2), merge_mode='mul')(merge_layer)\n",
    "drop_3 =  Dropout(0.5)(bidir_m)\n",
    "softmax_1 = Dense(max_span_begin, activation='softmax')(bidir_m)\n",
    "softmax_2 = Dense(max_span_end, activation='softmax')(bidir_m)\n",
    "model = Model(inputs=[context_input, ques_input], outputs=[softmax_1, softmax_2])\n",
    "opt = k.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      " - 546s - loss: 14.0659 - dense_1_loss: 7.0015 - dense_2_loss: 7.0644 - dense_1_acc: 0.0275 - dense_2_acc: 0.0046\n",
      "Epoch 2/150\n",
      " - 527s - loss: 13.2918 - dense_1_loss: 6.6059 - dense_2_loss: 6.6859 - dense_1_acc: 0.0279 - dense_2_acc: 0.0060\n",
      "Epoch 3/150\n",
      " - 527s - loss: 13.2521 - dense_1_loss: 6.5866 - dense_2_loss: 6.6655 - dense_1_acc: 0.0279 - dense_2_acc: 0.0051\n",
      "Epoch 4/150\n",
      " - 527s - loss: 13.2388 - dense_1_loss: 6.5808 - dense_2_loss: 6.6580 - dense_1_acc: 0.0279 - dense_2_acc: 0.0069\n",
      "Epoch 5/150\n",
      " - 527s - loss: 13.2213 - dense_1_loss: 6.5710 - dense_2_loss: 6.6503 - dense_1_acc: 0.0279 - dense_2_acc: 0.0066\n",
      "Epoch 6/150\n",
      " - 526s - loss: 13.2075 - dense_1_loss: 6.5640 - dense_2_loss: 6.6435 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 7/150\n",
      " - 528s - loss: 13.1986 - dense_1_loss: 6.5589 - dense_2_loss: 6.6397 - dense_1_acc: 0.0279 - dense_2_acc: 0.0070\n",
      "Epoch 8/150\n",
      " - 527s - loss: 13.1902 - dense_1_loss: 6.5554 - dense_2_loss: 6.6348 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 9/150\n",
      " - 526s - loss: 13.1808 - dense_1_loss: 6.5508 - dense_2_loss: 6.6301 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 10/150\n",
      " - 525s - loss: 13.1792 - dense_1_loss: 6.5489 - dense_2_loss: 6.6303 - dense_1_acc: 0.0279 - dense_2_acc: 0.0069\n",
      "Epoch 11/150\n",
      " - 526s - loss: 13.1770 - dense_1_loss: 6.5485 - dense_2_loss: 6.6286 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 12/150\n",
      " - 525s - loss: 13.1767 - dense_1_loss: 6.5493 - dense_2_loss: 6.6274 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 13/150\n",
      " - 527s - loss: 13.1757 - dense_1_loss: 6.5481 - dense_2_loss: 6.6275 - dense_1_acc: 0.0279 - dense_2_acc: 0.0070\n",
      "Epoch 14/150\n",
      " - 524s - loss: 13.1744 - dense_1_loss: 6.5477 - dense_2_loss: 6.6267 - dense_1_acc: 0.0279 - dense_2_acc: 0.0068\n",
      "Epoch 15/150\n",
      " - 524s - loss: 13.1728 - dense_1_loss: 6.5466 - dense_2_loss: 6.6263 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 16/150\n",
      " - 524s - loss: 13.1742 - dense_1_loss: 6.5475 - dense_2_loss: 6.6266 - dense_1_acc: 0.0279 - dense_2_acc: 0.0062\n",
      "Epoch 17/150\n",
      " - 526s - loss: 13.1730 - dense_1_loss: 6.5468 - dense_2_loss: 6.6262 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 18/150\n",
      " - 525s - loss: 13.1709 - dense_1_loss: 6.5453 - dense_2_loss: 6.6256 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 19/150\n",
      " - 526s - loss: 13.1706 - dense_1_loss: 6.5449 - dense_2_loss: 6.6258 - dense_1_acc: 0.0279 - dense_2_acc: 0.0070\n",
      "Epoch 20/150\n",
      " - 524s - loss: 13.1708 - dense_1_loss: 6.5461 - dense_2_loss: 6.6247 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 21/150\n",
      " - 525s - loss: 13.1818 - dense_1_loss: 6.5517 - dense_2_loss: 6.6301 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 22/150\n",
      " - 526s - loss: 13.1753 - dense_1_loss: 6.5479 - dense_2_loss: 6.6275 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 23/150\n",
      " - 526s - loss: 13.1721 - dense_1_loss: 6.5472 - dense_2_loss: 6.6249 - dense_1_acc: 0.0279 - dense_2_acc: 0.0066\n",
      "Epoch 24/150\n",
      " - 528s - loss: 13.1729 - dense_1_loss: 6.5462 - dense_2_loss: 6.6267 - dense_1_acc: 0.0279 - dense_2_acc: 0.0062\n",
      "Epoch 25/150\n",
      " - 528s - loss: 13.1724 - dense_1_loss: 6.5454 - dense_2_loss: 6.6270 - dense_1_acc: 0.0279 - dense_2_acc: 0.0067\n",
      "Epoch 26/150\n",
      " - 526s - loss: 13.1726 - dense_1_loss: 6.5468 - dense_2_loss: 6.6258 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 27/150\n",
      " - 529s - loss: 13.1721 - dense_1_loss: 6.5459 - dense_2_loss: 6.6262 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 28/150\n",
      " - 526s - loss: 13.1712 - dense_1_loss: 6.5467 - dense_2_loss: 6.6245 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 29/150\n",
      " - 527s - loss: 13.1720 - dense_1_loss: 6.5462 - dense_2_loss: 6.6257 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 30/150\n",
      " - 527s - loss: 13.1721 - dense_1_loss: 6.5458 - dense_2_loss: 6.6263 - dense_1_acc: 0.0279 - dense_2_acc: 0.0060\n",
      "Epoch 31/150\n",
      " - 526s - loss: 13.1723 - dense_1_loss: 6.5467 - dense_2_loss: 6.6256 - dense_1_acc: 0.0279 - dense_2_acc: 0.0070\n",
      "Epoch 32/150\n",
      " - 527s - loss: 13.1711 - dense_1_loss: 6.5459 - dense_2_loss: 6.6251 - dense_1_acc: 0.0279 - dense_2_acc: 0.0070\n",
      "Epoch 33/150\n",
      " - 526s - loss: 13.1723 - dense_1_loss: 6.5473 - dense_2_loss: 6.6251 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 34/150\n",
      " - 527s - loss: 13.1704 - dense_1_loss: 6.5464 - dense_2_loss: 6.6241 - dense_1_acc: 0.0279 - dense_2_acc: 0.0061\n",
      "Epoch 35/150\n",
      " - 525s - loss: 13.1695 - dense_1_loss: 6.5454 - dense_2_loss: 6.6240 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 36/150\n",
      " - 525s - loss: 13.1676 - dense_1_loss: 6.5441 - dense_2_loss: 6.6234 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 37/150\n",
      " - 530s - loss: 13.1672 - dense_1_loss: 6.5437 - dense_2_loss: 6.6235 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 38/150\n",
      " - 525s - loss: 13.1687 - dense_1_loss: 6.5452 - dense_2_loss: 6.6235 - dense_1_acc: 0.0279 - dense_2_acc: 0.0065\n",
      "Epoch 39/150\n",
      " - 526s - loss: 13.1672 - dense_1_loss: 6.5440 - dense_2_loss: 6.6233 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 40/150\n",
      " - 528s - loss: 13.1667 - dense_1_loss: 6.5442 - dense_2_loss: 6.6226 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 41/150\n",
      " - 527s - loss: 13.1682 - dense_1_loss: 6.5441 - dense_2_loss: 6.6241 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 42/150\n",
      " - 528s - loss: 13.1682 - dense_1_loss: 6.5433 - dense_2_loss: 6.6249 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 43/150\n",
      " - 524s - loss: 13.1655 - dense_1_loss: 6.5426 - dense_2_loss: 6.6229 - dense_1_acc: 0.0279 - dense_2_acc: 0.0056\n",
      "Epoch 44/150\n",
      " - 528s - loss: 13.1666 - dense_1_loss: 6.5440 - dense_2_loss: 6.6226 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 45/150\n",
      " - 527s - loss: 13.1655 - dense_1_loss: 6.5423 - dense_2_loss: 6.6232 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 46/150\n",
      " - 526s - loss: 13.1684 - dense_1_loss: 6.5439 - dense_2_loss: 6.6245 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 47/150\n",
      " - 528s - loss: 13.1674 - dense_1_loss: 6.5450 - dense_2_loss: 6.6224 - dense_1_acc: 0.0279 - dense_2_acc: 0.0066\n",
      "Epoch 48/150\n",
      " - 526s - loss: 13.1663 - dense_1_loss: 6.5437 - dense_2_loss: 6.6226 - dense_1_acc: 0.0279 - dense_2_acc: 0.0066\n",
      "Epoch 49/150\n",
      " - 528s - loss: 13.1654 - dense_1_loss: 6.5423 - dense_2_loss: 6.6231 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 50/150\n",
      " - 530s - loss: 13.1659 - dense_1_loss: 6.5432 - dense_2_loss: 6.6227 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 51/150\n",
      " - 532s - loss: 13.1659 - dense_1_loss: 6.5439 - dense_2_loss: 6.6220 - dense_1_acc: 0.0279 - dense_2_acc: 0.0068\n",
      "Epoch 52/150\n",
      " - 531s - loss: 13.1865 - dense_1_loss: 6.5534 - dense_2_loss: 6.6331 - dense_1_acc: 0.0279 - dense_2_acc: 0.0063\n",
      "Epoch 53/150\n",
      " - 528s - loss: 13.1732 - dense_1_loss: 6.5470 - dense_2_loss: 6.6263 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 54/150\n",
      " - 527s - loss: 13.1700 - dense_1_loss: 6.5459 - dense_2_loss: 6.6241 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 55/150\n",
      " - 526s - loss: 13.1618 - dense_1_loss: 6.5412 - dense_2_loss: 6.6206 - dense_1_acc: 0.0279 - dense_2_acc: 0.0060\n",
      "Epoch 56/150\n",
      " - 525s - loss: 13.1595 - dense_1_loss: 6.5396 - dense_2_loss: 6.6199 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 57/150\n",
      " - 525s - loss: 13.1573 - dense_1_loss: 6.5388 - dense_2_loss: 6.6185 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 58/150\n",
      " - 528s - loss: 13.1598 - dense_1_loss: 6.5400 - dense_2_loss: 6.6198 - dense_1_acc: 0.0279 - dense_2_acc: 0.0072\n",
      "Epoch 59/150\n",
      " - 528s - loss: 13.1601 - dense_1_loss: 6.5399 - dense_2_loss: 6.6202 - dense_1_acc: 0.0279 - dense_2_acc: 0.0064\n",
      "Epoch 60/150\n",
      " - 527s - loss: 13.1576 - dense_1_loss: 6.5399 - dense_2_loss: 6.6176 - dense_1_acc: 0.0279 - dense_2_acc: 0.0066\n",
      "Epoch 61/150\n",
      " - 525s - loss: 13.1581 - dense_1_loss: 6.5400 - dense_2_loss: 6.6181 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 62/150\n",
      " - 529s - loss: 13.1580 - dense_1_loss: 6.5399 - dense_2_loss: 6.6181 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 63/150\n",
      " - 527s - loss: 13.1586 - dense_1_loss: 6.5393 - dense_2_loss: 6.6193 - dense_1_acc: 0.0279 - dense_2_acc: 0.0067\n",
      "Epoch 64/150\n",
      " - 528s - loss: 13.1561 - dense_1_loss: 6.5378 - dense_2_loss: 6.6182 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 65/150\n",
      " - 526s - loss: 13.1537 - dense_1_loss: 6.5376 - dense_2_loss: 6.6161 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/150\n",
      " - 525s - loss: 13.1474 - dense_1_loss: 6.5344 - dense_2_loss: 6.6130 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 67/150\n",
      " - 528s - loss: 13.1437 - dense_1_loss: 6.5317 - dense_2_loss: 6.6119 - dense_1_acc: 0.0279 - dense_2_acc: 0.0070\n",
      "Epoch 68/150\n",
      " - 526s - loss: 13.1399 - dense_1_loss: 6.5296 - dense_2_loss: 6.6103 - dense_1_acc: 0.0279 - dense_2_acc: 0.0070\n",
      "Epoch 69/150\n",
      " - 528s - loss: 13.1369 - dense_1_loss: 6.5284 - dense_2_loss: 6.6085 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 70/150\n",
      " - 527s - loss: 13.1353 - dense_1_loss: 6.5279 - dense_2_loss: 6.6074 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 71/150\n",
      " - 529s - loss: 13.1288 - dense_1_loss: 6.5243 - dense_2_loss: 6.6044 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 72/150\n",
      " - 530s - loss: 13.1214 - dense_1_loss: 6.5200 - dense_2_loss: 6.6014 - dense_1_acc: 0.0279 - dense_2_acc: 0.0074\n",
      "Epoch 73/150\n",
      " - 526s - loss: 13.1141 - dense_1_loss: 6.5169 - dense_2_loss: 6.5972 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 74/150\n",
      " - 527s - loss: 13.1062 - dense_1_loss: 6.5122 - dense_2_loss: 6.5940 - dense_1_acc: 0.0279 - dense_2_acc: 0.0081\n",
      "Epoch 75/150\n",
      " - 530s - loss: 13.1004 - dense_1_loss: 6.5093 - dense_2_loss: 6.5911 - dense_1_acc: 0.0279 - dense_2_acc: 0.0075\n",
      "Epoch 76/150\n",
      " - 526s - loss: 13.0928 - dense_1_loss: 6.5047 - dense_2_loss: 6.5881 - dense_1_acc: 0.0279 - dense_2_acc: 0.0078\n",
      "Epoch 77/150\n",
      " - 527s - loss: 13.0873 - dense_1_loss: 6.5030 - dense_2_loss: 6.5844 - dense_1_acc: 0.0279 - dense_2_acc: 0.0082\n",
      "Epoch 78/150\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4c471434a6c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model_history = model.fit([c_data[:train], qn_data[:train]],\n\u001b[1;32m      2\u001b[0m                           \u001b[0;34m[\u001b[0m\u001b[0mbegin_ans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_ans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                           verbose=2,batch_size=batch_size, epochs=150)\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_history = model.fit([c_data[:train], qn_data[:train]],\n",
    "                          [begin_ans[:train], end_ans[:train]], \n",
    "                          verbose=2,batch_size=batch_size, epochs=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is stopped after 77 epochs as there seems to be no improvement in performance for more than 20 epochs. Further continuation would lead to loss in time and memory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
