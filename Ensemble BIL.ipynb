{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPLEMENTING ENSEMBLE OF BIDIRECTIONAL LSTM AND LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import io\n",
    "import nltk\n",
    "import h5py\n",
    "import keras as k\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Dense, Dropout, RepeatVector, Activation, merge, Lambda, Flatten, Reshape,Permute\n",
    "from keras.layers import LSTM, Bidirectional, TimeDistributed, GRU\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import concatenate\n",
    "from sklearn.metrics import f1_score\n",
    "from keras_self_attention import SeqSelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open( 'glove.6B.100d.txt',encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = h5py.File('context.h5','r')\n",
    "questions = h5py.File('questions.h5','r')\n",
    "answers = h5py.File('answers.h5','r')\n",
    "ans_begin = h5py.File('begin.h5','r')\n",
    "ans_end = h5py.File('end.h5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_data = context['context'][:]\n",
    "qn_data = questions['questions'][:]\n",
    "ans_data = answers['answers'][:]\n",
    "begin_ans = ans_begin['begin'][:]\n",
    "end_ans = ans_end['end'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loding vocabulary\n",
    "word_index = np.load('words.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, 100))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word_index) + 1\n",
    "#embedding_vector_length = 50\n",
    "batch_size = 64\n",
    "max_span_begin = np.amax(begin_ans)\n",
    "max_span_end = np.amax(end_ans)\n",
    "train = 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "119616"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Vocab Size\")\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_input = Input(shape=(700, ), dtype='int32', name='c_data')\n",
    "embed_c = Embedding(input_dim=vocab_size, output_dim=100, weights=[embedding_matrix], \n",
    "              input_length=700, trainable=False)(context_input)\n",
    "lstm_1 = LSTM(256, return_sequences=True, implementation=2)(embed_c)\n",
    "bidir_1 = Bidirectional(LSTM(500, return_sequences=True, implementation=2), merge_mode='concat')(lstm_1)\n",
    "bidir_12 = Bidirectional(LSTM(500, return_sequences=True, implementation=2), merge_mode='concat')(bidir_1)\n",
    "drop_1 = Dropout(0.5)(bidir_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques_input = Input(shape=(100, ), dtype='int32', name='qn_data')\n",
    "embed_q = Embedding(input_dim=vocab_size, output_dim=100, weights=[embedding_matrix], \n",
    "              input_length=100, trainable=False)(ques_input)\n",
    "lstm_2 = LSTM(256, return_sequences=True, implementation=2)(embed_q)\n",
    "bidir_2 = Bidirectional(LSTM(500, return_sequences=True, implementation=2), merge_mode='concat')(lstm_2)\n",
    "bidir_22 = Bidirectional(LSTM(500, return_sequences=True, implementation=2), merge_mode='concat')(bidir_2)\n",
    "drop_2 = Dropout(0.5)(bidir_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "c_data (InputLayer)             (None, 700)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "qn_data (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 700, 100)     11961600    c_data[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 100, 100)     11961600    qn_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 700, 256)     365568      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 100, 256)     365568      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 700, 1000)    3028000     lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 100, 1000)    3028000     lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 700, 1000)    6004000     bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 100, 1000)    6004000     bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 700, 1000)    0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 100, 1000)    0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 800, 1000)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 500)          6004000     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3126)         1566126     bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3136)         1571136     bidirectional_5[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 51,859,598\n",
      "Trainable params: 27,936,398\n",
      "Non-trainable params: 23,923,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "merge_layer = concatenate([drop_1, drop_2], axis=1)\n",
    "bidir_3 = Bidirectional(LSTM(500, implementation=2), merge_mode='mul')(merge_layer)\n",
    "drop_3 =  Dropout(0.4)(bidir_3)\n",
    "softmax_1 = Dense(max_span_begin, activation='softmax')(bidir_3)\n",
    "softmax_2 = Dense(max_span_end, activation='softmax')(bidir_3)\n",
    "model = Model(inputs=[context_input, ques_input], outputs=[softmax_1, softmax_2])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 1962s - loss: 14.1034 - dense_1_loss: 7.0156 - dense_2_loss: 7.0878 - dense_1_acc: 0.0274 - dense_2_acc: 0.0032\n",
      "Epoch 2/100\n",
      " - 1939s - loss: 13.3732 - dense_1_loss: 6.6457 - dense_2_loss: 6.7275 - dense_1_acc: 0.0280 - dense_2_acc: 0.0058\n",
      "Epoch 3/100\n",
      " - 1940s - loss: 13.3343 - dense_1_loss: 6.6257 - dense_2_loss: 6.7086 - dense_1_acc: 0.0280 - dense_2_acc: 0.0048\n",
      "Epoch 4/100\n",
      " - 1941s - loss: 13.3321 - dense_1_loss: 6.6259 - dense_2_loss: 6.7062 - dense_1_acc: 0.0280 - dense_2_acc: 0.0048\n",
      "Epoch 5/100\n",
      " - 1940s - loss: 13.3299 - dense_1_loss: 6.6254 - dense_2_loss: 6.7045 - dense_1_acc: 0.0280 - dense_2_acc: 0.0046\n",
      "Epoch 6/100\n",
      " - 1939s - loss: 13.3277 - dense_1_loss: 6.6239 - dense_2_loss: 6.7038 - dense_1_acc: 0.0273 - dense_2_acc: 0.0054\n",
      "Epoch 7/100\n",
      " - 1939s - loss: 13.3250 - dense_1_loss: 6.6210 - dense_2_loss: 6.7040 - dense_1_acc: 0.0280 - dense_2_acc: 0.0059\n",
      "Epoch 8/100\n",
      " - 1939s - loss: 13.3240 - dense_1_loss: 6.6225 - dense_2_loss: 6.7015 - dense_1_acc: 0.0280 - dense_2_acc: 0.0050\n",
      "Epoch 9/100\n",
      " - 1940s - loss: 13.6145 - dense_1_loss: 6.7698 - dense_2_loss: 6.8447 - dense_1_acc: 0.0265 - dense_2_acc: 0.0050\n",
      "Epoch 10/100\n",
      " - 1939s - loss: 13.2818 - dense_1_loss: 6.6019 - dense_2_loss: 6.6800 - dense_1_acc: 0.0279 - dense_2_acc: 0.0059\n",
      "Epoch 11/100\n",
      " - 1940s - loss: 13.2132 - dense_1_loss: 6.5671 - dense_2_loss: 6.6461 - dense_1_acc: 0.0279 - dense_2_acc: 0.0064\n",
      "Epoch 12/100\n",
      " - 1940s - loss: 13.1915 - dense_1_loss: 6.5552 - dense_2_loss: 6.6363 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 13/100\n",
      " - 1939s - loss: 13.1793 - dense_1_loss: 6.5503 - dense_2_loss: 6.6291 - dense_1_acc: 0.0279 - dense_2_acc: 0.0066\n",
      "Epoch 14/100\n",
      " - 1939s - loss: 13.1739 - dense_1_loss: 6.5481 - dense_2_loss: 6.6258 - dense_1_acc: 0.0279 - dense_2_acc: 0.0069\n",
      "Epoch 15/100\n",
      " - 1939s - loss: 13.1666 - dense_1_loss: 6.5433 - dense_2_loss: 6.6233 - dense_1_acc: 0.0279 - dense_2_acc: 0.0068\n",
      "Epoch 16/100\n",
      " - 1939s - loss: 13.1638 - dense_1_loss: 6.5423 - dense_2_loss: 6.6215 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 17/100\n",
      " - 1939s - loss: 13.1636 - dense_1_loss: 6.5421 - dense_2_loss: 6.6215 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 18/100\n",
      " - 1939s - loss: 13.1615 - dense_1_loss: 6.5400 - dense_2_loss: 6.6215 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 19/100\n",
      " - 1939s - loss: 13.1599 - dense_1_loss: 6.5402 - dense_2_loss: 6.6196 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 20/100\n",
      " - 1939s - loss: 13.1600 - dense_1_loss: 6.5407 - dense_2_loss: 6.6193 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 21/100\n",
      " - 1939s - loss: 13.1559 - dense_1_loss: 6.5391 - dense_2_loss: 6.6168 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 22/100\n",
      " - 1940s - loss: 13.1563 - dense_1_loss: 6.5385 - dense_2_loss: 6.6178 - dense_1_acc: 0.0279 - dense_2_acc: 0.0071\n",
      "Epoch 23/100\n",
      " - 1939s - loss: 13.1518 - dense_1_loss: 6.5366 - dense_2_loss: 6.6152 - dense_1_acc: 0.0280 - dense_2_acc: 0.0072\n",
      "Epoch 24/100\n",
      " - 1939s - loss: 13.1518 - dense_1_loss: 6.5366 - dense_2_loss: 6.6151 - dense_1_acc: 0.0280 - dense_2_acc: 0.0072\n",
      "Epoch 25/100\n",
      " - 1939s - loss: 13.1477 - dense_1_loss: 6.5339 - dense_2_loss: 6.6138 - dense_1_acc: 0.0280 - dense_2_acc: 0.0070\n",
      "Epoch 26/100\n",
      " - 1938s - loss: 13.1473 - dense_1_loss: 6.5333 - dense_2_loss: 6.6140 - dense_1_acc: 0.0280 - dense_2_acc: 0.0072\n",
      "Epoch 27/100\n",
      " - 1939s - loss: 13.1445 - dense_1_loss: 6.5323 - dense_2_loss: 6.6122 - dense_1_acc: 0.0280 - dense_2_acc: 0.0072\n",
      "Epoch 28/100\n",
      " - 1939s - loss: 13.1443 - dense_1_loss: 6.5323 - dense_2_loss: 6.6120 - dense_1_acc: 0.0280 - dense_2_acc: 0.0072\n",
      "Epoch 29/100\n",
      " - 1939s - loss: 13.1446 - dense_1_loss: 6.5331 - dense_2_loss: 6.6116 - dense_1_acc: 0.0280 - dense_2_acc: 0.0072\n",
      "Epoch 30/100\n",
      " - 1939s - loss: 13.1443 - dense_1_loss: 6.5325 - dense_2_loss: 6.6117 - dense_1_acc: 0.0280 - dense_2_acc: 0.0072\n",
      "Epoch 31/100\n",
      " - 1939s - loss: 13.1450 - dense_1_loss: 6.5328 - dense_2_loss: 6.6122 - dense_1_acc: 0.0280 - dense_2_acc: 0.0072\n",
      "Epoch 32/100\n",
      " - 1939s - loss: 13.1436 - dense_1_loss: 6.5320 - dense_2_loss: 6.6116 - dense_1_acc: 0.0280 - dense_2_acc: 0.0072\n",
      "Epoch 33/100\n",
      " - 1939s - loss: 13.1440 - dense_1_loss: 6.5329 - dense_2_loss: 6.6111 - dense_1_acc: 0.0280 - dense_2_acc: 0.0072\n",
      "Epoch 34/100\n",
      " - 1940s - loss: 13.1461 - dense_1_loss: 6.5338 - dense_2_loss: 6.6123 - dense_1_acc: 0.0280 - dense_2_acc: 0.0072\n",
      "Epoch 35/100\n",
      " - 1938s - loss: 13.1456 - dense_1_loss: 6.5338 - dense_2_loss: 6.6118 - dense_1_acc: 0.0280 - dense_2_acc: 0.0072\n",
      "Epoch 36/100\n",
      " - 1939s - loss: 13.1625 - dense_1_loss: 6.5418 - dense_2_loss: 6.6207 - dense_1_acc: 0.0280 - dense_2_acc: 0.0072\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9651b291be53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model_history = model.fit([c_data[:train], qn_data[:train]],\n\u001b[1;32m      2\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mbegin_ans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_ans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                          batch_size=batch_size, epochs=100)\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_history = model.fit([c_data[:train], qn_data[:train]],\n",
    "                        [begin_ans[:train], end_ans[:train]], verbose=2,\n",
    "                         batch_size=batch_size, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopping the Model, since there seems to be no improvement in the model performance for more than 10 epochs. Each epoch takes about 32 minutes in a GPU. This seems to be a waste of memory and time if run further."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p27",
   "language": "python",
   "name": "conda_amazonei_mxnet_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
